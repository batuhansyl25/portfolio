import { marked } from 'marked';

// Blog post data - in a real app, this would be fetched from files
const blogPosts = {
  '1-go-redis': {
    title: "Go + Redis: Designing Fast Queues for Real-Time Workloads",
    date: "December 2024",
    readTime: "8 min read",
    description: "A deep dive into building distributed queue systems in Go using Redis Streams. â†’ Improved system latency by 85% and eliminated memory leaks in production.",
    content: `Real-time execution is critical in Web3 applications. Users expect instant blockchain responses â€” but balancing performance and reliability at scale is no small task.

## Problem: High Latency & Memory Leaks
While building compute pipelines for the **OpenGPU** project, we ran into several issues:

- **High Latency:** Go's built-in channels couldn't keep up under burst loads.  
- **Memory Leaks:** Long-lived goroutines piled up, consuming memory.  
- **Scalability Limits:** Channels were not enough for thousands of concurrent jobs.

## Solution: Redis Streams + Go Worker Pool
We built a distributed queue system using **Redis Streams** and a **Go worker pool**:

\`\`\`go
type WorkerPool struct {
    workers  int
    jobQueue chan Job
    quit     chan bool
    redis    *redis.Client
}

func (wp *WorkerPool) Start() {
    for i := 0; i < wp.workers; i++ {
        go wp.worker(i)
    }
}

func (wp *WorkerPool) worker(id int) {
    for {
        select {
        case job := <-wp.jobQueue:
            wp.processJob(job)
        case <-wp.quit:
            return
        }
    }
}
\`\`\`

### Key Implementation Details

**Redis Streams Configuration:**
\`\`\`go
// Create stream for job processing
XADD jobs * type "compute" payload "{...}" priority "high"

// Consumer group for load balancing
XGROUP CREATE jobs workers $ MKSTREAM
\`\`\`

## Results ðŸš€
The performance improvements were significant:

- **85% Latency Reduction:** Average processing time dropped from 2.3s to 0.3s
- **Memory Usage:** 60% decrease, completely eliminated memory leaks
- **Throughput:** Now handles 10,000+ requests per second
- **Reliability:** 99.9% uptime with automatic failover

## Production Best Practices

### 1. Connection Pooling
Always use connection pooling for Redis to avoid connection overhead:

\`\`\`go
client := redis.NewClient(&redis.Options{
    PoolSize:     runtime.NumCPU() * 10,
    MinIdleConns: 5,
    MaxRetries:   3,
    DialTimeout:  5 * time.Second,
})
\`\`\`

### 2. Error Handling & Retry Logic
Implement robust error handling with exponential backoff:

\`\`\`go
func (wp *WorkerPool) processJobWithRetry(job Job) error {
    maxRetries := 3
    for i := 0; i < maxRetries; i++ {
        if err := wp.processJob(job); err == nil {
            return nil
        }
        time.Sleep(time.Duration(i+1) * time.Second)
    }
    return wp.sendToDeadLetterQueue(job)
}
\`\`\`

This implementation now powers OpenGPU's backend, handling enterprise-grade workloads with thousands of concurrent users. The combination of Go's concurrency model and Redis's persistence creates a robust foundation for real-time Web3 applications.`
  },
  '2-docker-web3': {
    title: "From Local to Prod: Dockerizing a Web3 Service with CI/CD",
    date: "December 2024",
    readTime: "10 min read",
    description: "How we automated the entire deployment process for OpenGPU with GitHub Actions and multi-stage Docker builds.",
    content: `Deploying Web3 services to production requires more than just \`docker run\`. You need robust CI/CD pipelines, proper secret management, and zero-downtime deployments. Here's how we built a bulletproof deployment system for our Web3 infrastructure.

## The Challenge: Complex Web3 Dependencies
Web3 services have unique deployment challenges:

- **Blockchain Connections:** Multiple RPC endpoints and network configurations
- **Secret Management:** Private keys, API keys, and wallet credentials
- **Environment Parity:** Local development must match production exactly
- **Rollback Strategy:** Failed deployments can't break user transactions

## Solution: Multi-Stage Docker + GitHub Actions

### 1. Multi-Stage Dockerfile
We use multi-stage builds to optimize image size and security:

\`\`\`dockerfile
# Build stage
FROM golang:1.21-alpine AS builder
WORKDIR /app
COPY go.mod go.sum ./
RUN go mod download
COPY . .
RUN CGO_ENABLED=0 GOOS=linux go build -o main ./cmd/server

# Production stage
FROM alpine:latest
RUN apk --no-cache add ca-certificates tzdata
WORKDIR /root/
COPY --from=builder /app/main .
COPY --from=builder /app/configs ./configs
EXPOSE 8080
CMD ["./main"]
\`\`\`

## Results & Metrics ðŸ“Š
Our deployment pipeline achieved:

- **Deployment Time:** Reduced from 2 hours to 15 minutes
- **Success Rate:** 99.99% deployment success rate
- **Rollback Time:** 30 seconds for emergency rollbacks
- **Zero Downtime:** 100% uptime during deployments
- **Security:** No secrets in code, all encrypted at rest

This deployment system now handles our production Web3 services with confidence. The combination of Docker, GitHub Actions, and AWS ECS creates a robust, scalable infrastructure that can handle enterprise workloads.`
  },
  '3-nextjs-web3': {
    title: "Next.js + Web3: Reliable Frontend Patterns That Don't Break",
    date: "December 2024",
    readTime: "12 min read",
    description: "Stable wallet connection patterns and SSR-safe rendering strategies for Web3 UIs.",
    content: `Building Web3 frontends with Next.js requires more than just connecting a wallet. You need robust error handling, state management, and seamless user experiences. Here are the battle-tested patterns we use in production.

## The Challenge: Web3 Frontend Complexity
Web3 frontends face unique challenges:

- **Wallet Compatibility:** Multiple wallet providers with different APIs
- **Network Switching:** Users on wrong networks need guidance
- **State Management:** Complex Web3 state across components
- **Error Handling:** Network failures, rejected transactions, and edge cases
- **Performance:** Heavy Web3 libraries affecting page load times

## Solution: Custom Hooks + Context Pattern

### 1. Web3 Context Provider
\`\`\`tsx
// contexts/Web3Context.tsx
import { createContext, useContext, useEffect, useState, ReactNode } from 'react';
import { ethers } from 'ethers';

interface Web3ContextType {
  account: string | null;
  provider: ethers.providers.Web3Provider | null;
  signer: ethers.Signer | null;
  chainId: number | null;
  isConnected: boolean;
  connect: () => Promise<void>;
  disconnect: () => void;
  switchNetwork: (chainId: number) => Promise<void>;
  error: string | null;
}
\`\`\`

## Results & Best Practices ðŸŽ¯
Our Web3 frontend patterns achieved:

- **99.9% Connection Success Rate** across different wallets
- **< 2s Load Time** with dynamic imports
- **Zero State Management Issues** with proper context usage
- **Comprehensive Error Handling** for all edge cases
- **Mobile-First Design** with responsive wallet interfaces

This architecture now powers multiple production Web3 applications, handling thousands of daily transactions with reliability and excellent user experience.`
  },
  '4-go-performance': {
    title: "Go Performance Optimization: From 100ms to 10ms Response Times",
    date: "December 2024",
    readTime: "9 min read",
    content: `Optimizing Go applications for high-performance Web3 backends requires deep understanding of the runtime, memory management, and concurrency patterns. Here's how we achieved 10x performance improvements in our production systems.

## The Challenge: High-Latency Web3 APIs
Our initial Go backend was struggling with performance:

- **Response Times:** 100-200ms for simple API calls
- **Memory Usage:** 2GB+ for moderate traffic
- **CPU Spikes:** 80%+ during peak loads
- **Garbage Collection:** Frequent GC pauses affecting latency

## Solution: Multi-Layer Optimization Strategy

### 1. Memory Pool Optimization
\`\`\`go
// pools/object_pool.go
package pools

import "sync"

type ObjectPool struct {
    pool sync.Pool
}

func NewObjectPool(newFunc func() interface{}) *ObjectPool {
    return &ObjectPool{
        pool: sync.Pool{
            New: newFunc,
        },
    }
}
\`\`\`

## Results & Benchmarks ðŸ“Š
Our optimization efforts achieved remarkable results:

- **Response Time:** 100ms â†’ 10ms (90% improvement)
- **Memory Usage:** 2GB â†’ 512MB (75% reduction)
- **CPU Usage:** 80% â†’ 30% (62% reduction)
- **Throughput:** 1,000 â†’ 10,000 requests/second (10x increase)
- **GC Pauses:** 50ms â†’ 5ms (90% reduction)

This optimization strategy now powers our production Web3 backend, handling enterprise-scale workloads with sub-10ms response times and 99.99% uptime.`
  },
  '5-web3-security': {
    title: "Web3 Security: Protecting Smart Contracts and dApps from Common Vulnerabilities",
    date: "December 2024",
    readTime: "11 min read",
    content: `Web3 security is fundamentally different from traditional web security. With irreversible transactions and decentralized infrastructure, a single vulnerability can result in millions of dollars in losses. Here's our comprehensive security framework for building bulletproof Web3 applications.

## The Web3 Security Landscape
Web3 applications face unique security challenges:

- **Irreversible Transactions:** No chargebacks or refunds
- **Public Code:** Smart contracts are open source by nature
- **Economic Incentives:** High-value targets attract sophisticated attackers
- **Decentralized Infrastructure:** No central authority for dispute resolution
- **User Responsibility:** Users control their own private keys

## Common Vulnerabilities and Mitigations

### 1. Reentrancy Attacks
**The Problem:** External calls can re-enter the contract before state updates.

\`\`\`solidity
// VULNERABLE CODE
contract VulnerableBank {
    mapping(address => uint256) public balances;
    
    function withdraw(uint256 amount) public {
        require(balances[msg.sender] >= amount);
        
        // External call before state update - VULNERABLE!
        (bool success, ) = msg.sender.call{value: amount}("");
        require(success);
        
        balances[msg.sender] -= amount; // Too late!
    }
}
\`\`\`

**The Solution:** Use the Checks-Effects-Interactions pattern:

\`\`\`solidity
// SECURE CODE
contract SecureBank {
    mapping(address => uint256) public balances;
    mapping(address => bool) private locked;
    
    modifier noReentrancy() {
        require(!locked[msg.sender], "ReentrancyGuard: reentrant call");
        locked[msg.sender] = true;
        _;
        locked[msg.sender] = false;
    }
}
\`\`\`

## Results & Security Metrics ðŸ“Š
Our security framework achieved:

- **Zero Critical Vulnerabilities** in production contracts
- **99.99% Uptime** with emergency response capabilities
- **< 1 Hour** incident response time
- **100% Code Coverage** in security tests
- **Quarterly Security Audits** by third-party firms

This security framework now protects millions of dollars in Web3 assets across multiple production applications, with zero security incidents to date.`
  }
};

export const getBlogPost = (id) => {
  return blogPosts[id] || null;
};

export const getAllBlogPosts = () => {
  return Object.keys(blogPosts).map(id => ({
    id,
    ...blogPosts[id]
  }));
};

export const parseMarkdown = (content) => {
  return marked(content);
};
